{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-18 18:56:56.653107: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-18 18:56:56.653130: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from tensorflow import keras\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import os\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import dlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-18 18:56:59.322436: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-12-18 18:56:59.350165: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:c1:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.6705GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2021-12-18 18:56:59.350300: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-18 18:56:59.350354: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2021-12-18 18:56:59.350393: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2021-12-18 18:56:59.350431: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2021-12-18 18:56:59.350469: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2021-12-18 18:56:59.350506: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2021-12-18 18:56:59.350543: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2021-12-18 18:56:59.350581: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2021-12-18 18:56:59.350589: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1766] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-12-18 18:56:59.351062: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-18 18:56:59.352767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-12-18 18:56:59.352816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      \n"
     ]
    }
   ],
   "source": [
    "## Load model\n",
    "model = tf.keras.models.load_model(\"/home/data/data/kodeiri/ML_project/saved_model/my_model4\")\n",
    "## Load heatmap template for each class\n",
    "HM_shape = (100,100,3) ## template heatmap shape DO NOT CHANGE, only if the original shape changed before saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load detector libraries\n",
    "detector = dlib.cnn_face_detection_model_v1('/home/data/data/kodeiri/ML_project/dogHeadDetector.dat')\n",
    "predictor = dlib.shape_predictor('/home/data/data/kodeiri/ML_project/landmarkDetector.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## heatmap loader\n",
    "def Hm_loader(path):\n",
    "    template_pre =np.loadtxt(path)\n",
    "    template = template_pre.reshape(template_pre.shape[0], template_pre.shape[1] // 3, 3)\n",
    "    return template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "young_path = \"/home/data/data/kodeiri/ML_project/HM/Young.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_path = \"/home/data/data/kodeiri/ML_project/HM/Adult.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "senior_path = \"/home/data/data/kodeiri/ML_project/HM/Senior.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Young_template = Hm_loader(young_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.149321266968325\n",
      "[0. 0. 0.] [ 1.71493213  4.29864253 23.14932127]\n"
     ]
    }
   ],
   "source": [
    "Adult_template = Hm_loader(adult_path)\n",
    "smallest = Adult_template.min(axis=(0, 1))\n",
    "\n",
    "largest = Adult_template.max(axis=(0, 1))\n",
    "print(max(largest))\n",
    "print(smallest, largest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Senior_template = Hm_loader(senior_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wyszukiwanie zdjęcia na białym tle\n",
    "def photo_detector(src_image):\n",
    "\n",
    "    img_in = cv2.cvtColor(src_image, cv2.COLOR_BGR2RGB)\n",
    "    # img = cv2.resize(img, dsize=None, fx=0.5, fy=0.5)\n",
    "    \n",
    "    gray = cv2.cvtColor(img_in, cv2.COLOR_BGR2GRAY)\n",
    "    height, width = gray.shape\n",
    "\n",
    "    ret, thresh = cv2.threshold(gray, 254, 255, 1)\n",
    "\n",
    "    # f, axarr = plt.subplots(1,3)\n",
    "\n",
    "    photo_width = np.count_nonzero(thresh == 255, axis=0).max()\n",
    "    photo_height = np.count_nonzero(thresh == 0, axis=1).min()\n",
    "\n",
    "    column, row, photo_width, photo_height = cv2.boundingRect(thresh)\n",
    "\n",
    "    # axarr[0].imshow(thresh)\n",
    "    # axarr[1].imshow(thresh[row:row+photo_height, column:column+photo_width])\n",
    "    # axarr[2].imshow(img_in[row:row+photo_height, column:column+photo_width])\n",
    "    # print((column, row, photo_width, photo_height))\n",
    "    return (column, row, photo_width, photo_height)\n",
    "\n",
    "# wycinanie zdjęcia z biełego tła oraz reskalowanie do 100x100\n",
    "def image_crop(src_image, coordinates, res=(100, 100)):\n",
    "\n",
    "    column, row, photo_width, photo_height = coordinates\n",
    "    result_image = src_image[row:row + photo_height, column: column + photo_width]\n",
    "    return cv2.resize(result_image, res)\n",
    "    # return img_in[]\n",
    "    # for rows in thresh:\n",
    "    \n",
    "    # img2, contours, hierarchy = cv2.findContours(thresh, 1, 2)\n",
    "    # plt.imshow(img2)\n",
    "    \n",
    "    # print(np.where(thresh == 255) )\n",
    " \n",
    "    # mask = 255 - mask\n",
    "\n",
    "    # mask = cv2.GaussianBlur(mask, (0,0), sigmaX=2, sigmaY=2, borderType = cv2.BORDER_DEFAULT)\n",
    "\n",
    "    # cnts = cv2.findContours(gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
    "    # cnt = sorted(cnts, key=cv2.contourArea)[-1]\n",
    "\n",
    "    # x,y,w,h = cv2.boundingRect(cnt)\n",
    "    # print(x, y, w, h)\n",
    "    # dst = img_in[y:y+h, x:x+w]\n",
    "\n",
    "    # result = img_in.copy()\n",
    "    # result = cv2.cvtColor(result, cv2.COLOR_BGR2BGRA)\n",
    "    # result[:, :, 3] = mask\n",
    "    # img_in[:,:,3] = mask\n",
    "    # plt.imshow(img_in)\n",
    "\n",
    "    # dets = detector(img_in, upsample_num_times=1)\n",
    "\n",
    "    # #print(dets)\n",
    "\n",
    "    # img_result = img_in.copy()\n",
    "\n",
    "    # for i, d in enumerate(dets):\n",
    "    #     print(\"Detection {}: Left: {} Top: {} Right: {} Bottom: {} Confidence: {}\".format(i, d.rect.left(), d.rect.top(), d.rect.right(), d.rect.bottom(), d.confidence))\n",
    "\n",
    "    #     ((x1, y1), (x2, y2)) = (d.rect.left(), d.rect.top()), (d.rect.right(), d.rect.bottom())\n",
    "    #     if y1 < 0:\n",
    "    #         y1 = 0\n",
    "    #     if x1 < 0:\n",
    "    #         x1 = 0\n",
    "    #     if x2 < 0:\n",
    "    #         x2 = 0\n",
    "    #     if y2 < 0:\n",
    "    #         y2 = 0 \n",
    "\n",
    "\n",
    "    # return ((x1, y1), (x2, y2))\n",
    "\n",
    "# znajdywanie featerów na pieskach, tutaj każde zdjęcie zostaje podane operacji wyrównania histogramu, poczym cechy zostają wyciagnięte\n",
    "def features_detector(src_image):\n",
    "\n",
    "    ycrvb_img = cv2.cvtColor(src_image, cv2.COLOR_BGR2YCrCb)\n",
    "    ycrvb_img[:, :, 0] = cv2.equalizeHist(ycrvb_img[:, :, 0])\n",
    "\n",
    "    yuv_img = cv2.cvtColor(src_image, cv2.COLOR_BGR2YUV)\n",
    "    yuv_img[:, :, 0] = cv2.equalizeHist(yuv_img[:, :, 0])\n",
    "\n",
    "    equlized_img1 = cv2.cvtColor(ycrvb_img, cv2.COLOR_YCrCb2BGR)\n",
    "    equlized_img2 = cv2.cvtColor(yuv_img, cv2.COLOR_YUV2BGR)\n",
    "\n",
    "    # f, axarr = plt.subplots(1,4)\n",
    "    # axarr[0].imshow(image)\n",
    "    # axarr[1].imshow(ycrvb_img)\n",
    "    # axarr[2].imshow(equlized_img1)\n",
    "    # axarr[3].imshow(equlized_img2)\n",
    "\n",
    "    dets = detector(equlized_img1, upsample_num_times=1)\n",
    "    # if len(dets):\n",
    "    if len(dets):\n",
    "        shape = predictor(equlized_img1, dets.pop().rect)\n",
    "        (forehead, right_ear, right_eye, nose, left_ear, left_eye) = face_utils.shape_to_np(shape)\n",
    "\n",
    "        return (forehead, right_ear, right_eye, nose, left_ear, left_eye)\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obraca zdjęcie tak, że linia oczu jest horyzontalnie\n",
    "def img_rotate(src_image, face_features, res=(100, 100)):\n",
    "\n",
    "    (forehead, right_ear, (x2, y2), nose, left_ear, (x1, y1)) = face_features\n",
    "    \n",
    "    slope = (y2 - y1) / (x2 - x1)\n",
    "    rad = np.arctan2(y2 - y1, x2 - x1)\n",
    "    angle = np.rad2deg(rad)\n",
    "\n",
    "    cX = int(nose[0])\n",
    "    cY = int(nose[1])\n",
    "    rotationMatrix = cv2.getRotationMatrix2D((cX, cY), angle, 1.0)\n",
    "    rotatedImage = cv2.warpAffine(src_image, rotationMatrix, res)\n",
    "\n",
    "    # plt.imshow(rotatedImage)\n",
    "\n",
    "    return rotatedImage\n",
    "    \n",
    "def translate_image(src_image, translate_destination, feautres, feature_id=3, res=(100, 100)):\n",
    "    tX, tY = translate_destination\n",
    "    bX, bY = feautres[feature_id]\n",
    "\n",
    "    M = np.float32([[1, 0, tX - bX],[0, 1,  tY - bY]])\n",
    "\n",
    "    return_image = cv2.warpAffine(src_image, M, res)\n",
    "    return return_image\n",
    "\n",
    "def check_triangle_angles(face_features, max_angle = 70.0):\n",
    "    (forehead, right_ear, (x1, y1), (x2, y2), left_ear, (x3, y3)) = face_features\n",
    "\n",
    "    # calculate distance between dog eyes \n",
    "    a = np.sqrt((x1 - x3) ** 2 + (y1 - y3) ** 2)\n",
    "    # calculate distance between dog left eye and nose \n",
    "    b = np.sqrt((x2 - x3) ** 2 + (y2 - y3) ** 2)\n",
    "    # calculate distance between dog right eye and nose \n",
    "    c = np.sqrt((x1 - x2) ** 2 + (y1 - y2) ** 2)\n",
    "    \n",
    "    cos_a = (b ** 2 + c ** 2 - a ** 2) / (2 * b * c)\n",
    "    cos_b = (c ** 2 + a ** 2 - b ** 2) / (2 * a * c)\n",
    "    cos_c = (a ** 2 + b ** 2 - c ** 2) / (2 * a * b)\n",
    "\n",
    "    angle_a = np.rad2deg(np.arccos(cos_a))\n",
    "    angle_b = np.rad2deg(np.arccos(cos_b))\n",
    "    angle_c = np.rad2deg(np.arccos(cos_c))\n",
    "\n",
    "    # print(angle_a, angle_b, angle_c)\n",
    "    if angle_a < max_angle and angle_b < max_angle and angle_c < max_angle:\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Face_detector(img):\n",
    "    img_in = img\n",
    "\n",
    "    img_in = cv2.cvtColor(img_in, cv2.COLOR_BGR2RGB)\n",
    "    # img = cv2.resize(img, dsize=None, fx=0.5, fy=0.5)\n",
    "\n",
    "    \n",
    "    gray = cv2.cvtColor(img_in, cv2.COLOR_BGR2GRAY)\n",
    "    th, threshed = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY_INV) \n",
    "\n",
    "    cnts = cv2.findContours(gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
    "    cnt = sorted(cnts, key=cv2.contourArea)[-1]\n",
    "\n",
    "    x,y,w,h = cv2.boundingRect(cnt)\n",
    "    dst = img_in[y:y+h, x:x+w]\n",
    "\n",
    "    plt.imshow(dst)\n",
    "\n",
    "    dets = detector(img_in, upsample_num_times=1)\n",
    "\n",
    "    #print(dets)\n",
    "\n",
    "    img_result = img_in.copy()\n",
    "\n",
    "    for i, d in enumerate(dets):\n",
    "       # print(\"Detection {}: Left: {} Top: {} Right: {} Bottom: {} Confidence: {}\".format(i, d.rect.left(), d.rect.top(), d.rect.right(), d.rect.bottom(), d.confidence))\n",
    "\n",
    "        x1, y1 = d.rect.left(), d.rect.top()\n",
    " \n",
    "        x2, y2 = d.rect.right(), d.rect.bottom()\n",
    "        if y1 < 0:\n",
    "            y1 = 0\n",
    "        if x1 < 0:\n",
    "            x1 = 0\n",
    "        if x2 < 0:\n",
    "            x2 = 0\n",
    "        if y2 < 0:\n",
    "            y2 = 0 \n",
    "\n",
    "        #cv2.rectangle(img_result, pt1=(x1, y1), pt2=(x2, y2), thickness=2, color=(255,0,0), lineType=cv2.LINE_AA)\n",
    "        \n",
    "    shapes = []\n",
    "\n",
    "    \n",
    "\n",
    "    for i, d in enumerate(dets):\n",
    "        shape = predictor(img_in, d.rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        # for i, p in enumerate(shape):\n",
    "        shapes.append(shape)\n",
    "            #cv2.putText(img_result, str(i), tuple(p), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1, cv2.LINE_AA)\n",
    "    # cv2.circle(img_result, center=shapes[4], radius=0.5, color=(0,0,255), thickness=-1, lineType=cv2.LINE_AA)\n",
    "    # img_result = img_result[y1:y2,x1:x2]\n",
    "    # print(img_result.shape)\n",
    "    # img_result = cv2.resize(img_result,(100,100))\n",
    "    #img_out = cv2.cvtColor(img_result, cv2.COLOR_RGB2BGR)\n",
    "    #cv2.imwrite('img/%s_out%s' % (filename, ext), img_out)\n",
    "    #plt.figure(figsize=(16, 16))\n",
    "    # plt.imshow(img_result)\n",
    "    try:\n",
    "        return img_result, x1, x2, y1, y2\n",
    "    except:\n",
    "        return img_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## crop the dog before inputting into network. If no detection throw error\n",
    "\n",
    "def Image_preprocessor(input_path,res=100):\n",
    "    img = cv2.imread(input_path)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = x.astype(np.float32)\n",
    "    x/=255\n",
    "    return x\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load categories\n",
    "CATEGORIES = [\"Adult\", \"Senior\", \"Young\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predDecoder(prediction):\n",
    "    x = np.argmax(prediction)\n",
    "    #print(\"Prediction: \" + CATEGORIES[x])\n",
    "    prob = prediction[x]\n",
    "    print(\"Confidence: \"+ str(prob))\n",
    "    return (CATEGORIES[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "## function to crop images with face detector \n",
    "## before inputting to network\n",
    "## specify source folder and thrash folder\n",
    "## incorrect photos will be copied to thrash \n",
    "## and removed from the source\n",
    "## correct will be cropped and saved in the same\n",
    "## folder\n",
    "## run only ONCE on given folder\n",
    "def all_img_loop(src,thrash):\n",
    "  for filename in os.listdir(src):\n",
    "    string_e=src+filename\n",
    "    img = cv2.imread(string_e)\n",
    "    IMG_SIZE =100\n",
    "    try:\n",
    "      x, x1, x2, y1, y2 = Face_detector(img)\n",
    "      x = img[y1:y2,x1:x2]\n",
    "      x = cv2.resize(x,(IMG_SIZE,IMG_SIZE))\n",
    "      resized_image = x\n",
    "      # save same img\n",
    "      cv2.imwrite(string_e, resized_image)\n",
    "    except: ## if file not detected, copy to trash folder and remove from the source\n",
    "      wrong_address = thrash\n",
    "      shutil.copy(string_e,wrong_address) ## move incorrect files to other folder\n",
    "      os.remove(string_e)\n",
    "      continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_img_loop('/home/data/data/kodeiri/ML_project/dogs datasets/Petfinder_All/Senior_experimental/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_decoder(path,ground_truth, intensity=0.5, res=100):\n",
    "  #iteration_number=len(os.listdir(path))\n",
    "  iteration_number=5\n",
    "  i=0\n",
    "  cntr = 0\n",
    "  error_counter = 0\n",
    "  piclist=os.listdir(path)\n",
    "  hm_sum = np.zeros((100, 100, 3, 1))\n",
    "  for i in range (iteration_number):\n",
    "    img_path = path+piclist[i]\n",
    "    img = Image_preprocessor(img_path)\n",
    "    if img.size == 0:\n",
    "      error_counter = error_counter + 1\n",
    "      continue ## skip the iteration if object not detected\n",
    "      \n",
    "    preds = model.predict(img)[0]\n",
    "    predicted_class = predDecoder(preds)\n",
    "    print(\"Ground_truth: \"+ ground_truth)\n",
    "    print(\"Prediction: \" + predicted_class)\n",
    "    if predicted_class == ground_truth:\n",
    "      cntr=cntr+1\n",
    "    conv_layer = model.get_layer(index=0)\n",
    "    heatmap_model = tf.keras.models.Model([model.inputs], [conv_layer.output, model.output])\n",
    "    \n",
    "    with tf.GradientTape() as gtape:\n",
    "        conv_output, predictions = heatmap_model(img)\n",
    "        argmax=tf.argmax(predictions[0])\n",
    "        loss = predictions[:, argmax]\n",
    "        grads = gtape.gradient(loss, conv_output)\n",
    "        pooled_grads = K.mean(grads, axis=(0,1,2))\n",
    "\n",
    "\n",
    "    heatmap = tf.reduce_mean(tf.multiply(pooled_grads, conv_output), axis=-1)\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    max_heat = np.max(heatmap)\n",
    "    if max_heat == 0:\n",
    "        max_heat = 1e-10\n",
    "    heatmap /= max_heat\n",
    "    \n",
    "    img = cv2.imread(img_path) ## reload the original image without preprocessing to get facial features\n",
    "    \n",
    "    try:\n",
    "            x, x1, x2, y1, y2 = Face_detector(img)\n",
    "            x = img[y1:y2,x1:x2]\n",
    "            x =  cv2.resize(x,(res,res))\n",
    "            img = x\n",
    "    except:\n",
    "            print ('Error ocurred!')\n",
    "            continue\n",
    "\n",
    "    heatmap = heatmap.squeeze()\n",
    "    #plt.matshow(heatmap)\n",
    "    #plt.show()\n",
    "    heatmap = cv2.resize(heatmap, (res, res))\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255*heatmap), cv2.COLORMAP_HOT)\n",
    "    ref_img = heatmap * intensity + img\n",
    "    \n",
    "    ref_img = cv2.resize(ref_img, (res, res))\n",
    "    ref_img = cv2.cvtColor(ref_img.astype('float32'), cv2.COLOR_BGR2RGB)\n",
    "    ref_img = ref_img/np.amax(ref_img)\n",
    "\n",
    "\n",
    "    features = features_detector(img)\n",
    "    if len(features):\n",
    "      #print(\"Success1!\")\n",
    "      img = img_rotate(img, features, res=(res, res))\n",
    "      heatmap = img_rotate(heatmap, features, res=(res, res))\n",
    "\n",
    "    # wykrywanie featerów oraz translacja zdjęcia, tak aby nos znadował się w pozycji 50x50\n",
    "    if len(features):\n",
    "      #print(\"Success2!\")\n",
    "      img = translate_image(img, (50, 50), features, res=(res, res))\n",
    "      heatmap = translate_image(heatmap, (50, 50), features, res=(res, res))\n",
    "      hm_sum = np.append(hm_sum, heatmap.reshape((100, 100, 3, 1)), axis=3) ## to powinno iść w warunek niżej!\n",
    "\n",
    "    # sprawdzenie czy znaki charakterystyczne pyska psa spełniają odpowiednie założenie - kąt maskymalny nie mozę przekraczać konkretnej wartosći\n",
    "    if len(features) and check_triangle_angles(features, max_angle = 70.0):\n",
    "      print(\"Success3!\") ## czemu nie wchodzę w tę pętlę???\n",
    "      #hm_sum = np.append(hm_sum, heatmap.reshape((100, 100, 3, 1)), axis=3)\n",
    "\n",
    "    template_map = {\n",
    "\n",
    "      \"Adult\" : Adult_template,\n",
    "      \"Young\" : Young_template,\n",
    "      \"Senior\" : Senior_template\n",
    "\n",
    "    }\n",
    "    heat_mean_val = heatmap.reshape((100, 100, 3, 1))\n",
    "\n",
    "    b, g, r = cv2.split(heatmap)\n",
    "\n",
    "    b_mean = b.mean().flatten()\n",
    "    g_mean = g.mean().flatten()\n",
    "    r_mean = r.mean().flatten()\n",
    "\n",
    "    b_counts, b_bins = np.histogram(b_mean, range(257))\n",
    "    g_counts, g_bins = np.histogram(g_mean, range(257))\n",
    "    r_counts, r_bins = np.histogram(r_mean, range(257))\n",
    "\n",
    "\n",
    "    b_equalize = cv2.equalizeHist(b)\n",
    "    g_equalize = cv2.equalizeHist(g)\n",
    "    r_equalize = cv2.equalizeHist(r)\n",
    "    \n",
    "    b_equalize_mean = b_equalize.mean().flatten()\n",
    "    g_equalize_mean = g_equalize.mean().flatten()\n",
    "    r_equalize_mean = r_equalize.mean().flatten()\n",
    "\n",
    "    b_equalize_counts, b_equalize_bins = np.histogram(b_equalize_mean, range(257))\n",
    "    g_equalize_counts, g_equalize_bins = np.histogram(g_equalize_mean, range(257))\n",
    "    r_equalize_counts, r_equalize_bins = np.histogram(r_equalize_mean, range(257))\n",
    "\n",
    "\n",
    "    heatmap_equalize = cv2.merge((b_equalize, g_equalize, r_equalize))      \n",
    "    # hist = cv2.calcHist([heatmap],[0],None,[256],[0,256])\n",
    "    # plt.hist(hist.ravel(),256,[0,256]); \n",
    "    ref_img = heatmap_equalize + img\n",
    "\n",
    "    hist_fig, ax = plt.subplots(2, 2, figsize=(10, 10))\n",
    "    ax[0][0].matshow(heatmap)\n",
    "    ax[0][0].title.set_text('dog heatmap')\n",
    "    # ax[0][1].hist(cv2.calcHist(heatmap, [0], None,[256], [0,256]), color='b')\n",
    "    # ax[0][1].hist(cv2.calcHist(heatmap, [1], None,[256], [0,256]), color='g')\n",
    "    # ax[0][1].hist(cv2.calcHist(heatmap, [2], None,[256], [0,256]), color='r')\n",
    "    ax[0][1].bar(b_bins[:-1] - 0.5, b_counts, width=1, edgecolor='none', color='b')\n",
    "    ax[0][1].bar(g_bins[:-1] - 0.5, g_counts, width=1, edgecolor='none', color='g')\n",
    "    ax[0][1].bar(r_bins[:-1] - 0.5, r_counts, width=1, edgecolor='none', color='r')\n",
    "    ax[0][1].title.set_text('heatmap histogram')\n",
    "    ax[1][0].matshow(heatmap_equalize)\n",
    "    # ax[1][0].title.set_text(\"equalized heatmap\")\n",
    "    # ax[1][1].hist(cv2.calcHist(heatmap_equalize, [0], None, [12000], [0,256]), color='b')\n",
    "    # ax[1][1].hist(cv2.calcHist(heatmap_equalize, [1], None, [12000], [0,256]), color='g')\n",
    "    # ax[1][1].hist(cv2.calcHist(heatmap_equalize, [2], None, [12000], [0,256]), color='r')\n",
    "    ax[1][1].bar(b_equalize_bins[:-1] - 0.5, b_equalize_counts, width=1, edgecolor='none', color='b')\n",
    "    ax[1][1].bar(g_equalize_bins[:-1] - 0.5, g_equalize_counts, width=1, edgecolor='none', color='g')\n",
    "    ax[1][1].bar(r_equalize_bins[:-1] - 0.5, r_equalize_counts, width=1, edgecolor='none', color='r')\n",
    "    ax[1][1].title.set_text(\"equalized heatmap histogram \")\n",
    "    plt.show()\n",
    "\n",
    "    # heat_mean_val = heat_mean_val.mean(axis=3)\n",
    "    heat_mean_val = heat_mean_val.mean(axis=3)\n",
    "    if predicted_class != ground_truth:\n",
    "      print(\"Difference in prediction, calculating metric...\")\n",
    "\n",
    "      mean_difference_gt = template_map[ground_truth] - heat_mean_val\n",
    "      mean_difference_prediction = template_map[predicted_class] - heat_mean_val\n",
    "      \n",
    "      gt_metric =  MSE(template_map[ground_truth].flatten(),heat_mean_val.flatten()) ## flattening required to calculate MSE\n",
    "      pred_metric =  MSE(template_map[predicted_class].flatten(),heat_mean_val.flatten()) ## flattening required to calculate MSE\n",
    "      metric_matrix = [gt_metric,pred_metric]\n",
    "      print(\"Metric matrix: \")\n",
    "      print(metric_matrix)\n",
    "      \n",
    "      fig, ax = plt.subplots(2, 2, figsize=(10, 10))  \n",
    "      ax[0][0].matshow(mean_difference_gt)\n",
    "      ax[0][0].title.set_text('Ground truth template mean - prediction heatmap')\n",
    "      ax[0][1].matshow(mean_difference_prediction)\n",
    "      ax[0][1].title.set_text('Prediction template mean -  prediction heatmap')\n",
    "      ax[1][0].matshow(heatmap_equalize)\n",
    "      ax[1][0].title.set_text(\"Prediction heatmap\")\n",
    "      ax[1][1].matshow(ref_img)\n",
    "      ax[1][1].title.set_text(\"Prediction heatmap with image\")\n",
    "      plt.show()\n",
    "\n",
    "  print (\"Correct cases: \" + str(cntr))\n",
    "  print (\"Total cases: \" + str(iteration_number-error_counter))\n",
    "  print (\"Prediction accuracy: \" + str(cntr/(iteration_number-error_counter)))\n",
    "     # hm_sum = hm_sum[hm_sum != np.zeros((100, 100, 3))]\n",
    "  # print(hm_sum[hm_sum != np.zeros((100, 100, 3))])\n",
    "  # fig, ax = plt.subplots(1, 3, figsize=(20, 30))\n",
    "  # ax[0].matshow(hm_sum.sum(axis=3))\n",
    "  # ax[0].title.set_text('heatmaps sum')\n",
    "  # ax[1].matshow(hm_sum.mean(axis=3))\n",
    "  # ax[1].title.set_text('heatmaps mean')\n",
    "  # # print(hm_sum.min().shape)\n",
    "  # # hm_median = np.median((hm_sum - hm_sum.min()) / (hm_sum.max() - hm_sum.min()) , axis=3)\n",
    "  # hm_median = np.median((hm_sum - hm_sum.mean()) / hm_sum.std() , axis=3)\n",
    "  # ax[2].matshow(hm_median)\n",
    "  # ax[2].title.set_text('heatmaps median')\n",
    "  # # plt.matshow(hm_sum)\n",
    "  # plt.show()\n",
    "  return (mean_difference_gt, mean_difference_prediction)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senior_example = metric_decoder('/home/data/data/kodeiri/ML_project/test_photos_downloaded/Senior/',ground_truth=\"Senior\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_example = metric_decoder('/home/data/data/kodeiri/ML_project/Mix_no_yolo_aug/Adult/',ground_truth=\"Adult\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here is part for pooling resulting imagaes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinPooling2D(tf.keras.layers.MaxPool2D):\n",
    "\n",
    "    def __init__(self, pool_size=(2, 2), strides=None, padding='valid', data_format=None, **kwargs):\n",
    "        print(pool_size, strides, padding, data_format)\n",
    "        super(tf.keras.layers.MaxPooling2D, self).__init__(pool_size=pool_size, strides=strides, padding=padding, data_format=data_format, pool_function=self.pooling_function, **kwargs)\n",
    "\n",
    "    def pooling_function(inputs, ksize, strides, padding, data_format):\n",
    "        return -keras.backend.pool2d(-inputs, ksize, strides, padding, data_format, pool_mode='max')\n",
    "\n",
    "def min_pool(max_pool, input):\n",
    "    return -max_pool(-input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_pooling_model = keras.Sequential()\n",
    "# image_pooling_model =\n",
    "\n",
    "image_size = (100, 100);\n",
    "\n",
    "# avg_pool_2d = tf.keras.layers.AvgPool2D(pool_size=(10, 10), strides=(10, 10), padding='valid')\n",
    "# min_pool_2d = MinPooling2D(pool_size=(10, 10), strides=(10, 10), padding='valid')\n",
    "min_pool_2d_1 = tf.keras.layers.MaxPool2D(pool_size=(10, 10), strides=(2, 2), padding='valid')\n",
    "# min_pool_2d_2 = tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='valid')\n",
    "\n",
    "# output_pred = avg_pool_2d(senior_example[1])\n",
    "\n",
    "output_gt = min_pool(min_pool_2d_1, senior_example[0].reshape((1, 100, 100, 3)))\n",
    "plt.imshow(output_gt.numpy().reshape((output_gt.shape[1], output_gt.shape[2], output_gt.shape[3])))\n",
    "\n",
    "# output_gt = min_pool(min_pool_2d_1, output_gt)\n",
    "# plt.imshow(output_gt.numpy().reshape((output_gt.shape[1], output_gt.shape[2], output_gt.shape[3])))\n",
    "\n",
    "# output_gt = min_pool(min_pool_2d_1, output_gt)\n",
    "# plt.imshow(output_gt.numpy().reshape((output_gt.shape[1], output_gt.shape[2], output_gt.shape[3])))\n",
    "\n",
    "# output_gt = min_pool(min_pool_2d_1, output_gt)\n",
    "# plt.imshow(output_gt.numpy().reshape((output_gt.shape[1], output_gt.shape[2], output_gt.shape[3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Footprints druga ścieżka\n",
    "\n",
    "1. Zrobienie template heatmap dla danej choroby\n",
    "2. Zrobienie template zdrowego psa\n",
    "3. Pociąć zdjęcie wejścia na obszary ZROBIĆ ALE PÓŹNIEJ\n",
    "4. Zrobienie funkcji obliczającej metryki (użyć metryk o skończonej dziedzinie) dla zdjęcia które chcemy zbadać\n",
    "5. Obliczyć metryki dla zdjęcia wejściowego z template zdrowym i chorym\n",
    "6. Analizować wyniki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For development purposes, metrics will be calculated on adult template and young template\n",
    "## When the algorithm will work, they will be replaced by valid heatmaps of predicted examples\n",
    "def img_to_tensor(input_img):\n",
    "    output_img = tf.convert_to_tensor(input_img)\n",
    "    shapes = input_img.shape\n",
    "    output_img = tf.reshape(output_img,[1,shapes[0],shapes[1],shapes[2]])\n",
    "    return output_img\n",
    "\n",
    "\n",
    "input_heatmap = img_to_tensor(Adult_template)\n",
    "healthy_template = img_to_tensor(Young_template)\n",
    "sick_template = img_to_tensor(Senior_template)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_val_ssim (img1, img2=None, single_arg = False):\n",
    "    # function returning max pixel value occuring\n",
    "    # in a pair of images passed as 4D tf.tensors\n",
    "    if single_arg==True:\n",
    "        max1 = tf.math.reduce_max(img1,axis=(0, 1))\n",
    "        max1 = tf.math.reduce_max(max1,axis=(0, 1))\n",
    "        max_val = max1.numpy()\n",
    "        return max_val    \n",
    "    max1 = tf.math.reduce_max(img1,axis=(0, 1))\n",
    "    max1 = tf.math.reduce_max(max1,axis=(0, 1))\n",
    "    max2 = tf.math.reduce_max(img2,axis=(0, 1))\n",
    "    max2 = tf.math.reduce_max(max2,axis=(0, 1))\n",
    "    max_val = tf.math.maximum(max1,max2).numpy()\n",
    "    return max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import correlate as corr\n",
    "\n",
    "\n",
    "def metrics_calculator(input_pred,input_template):\n",
    "    MSE_metric = MSE(input_template.numpy().flatten(),input_pred.numpy().flatten())\n",
    "    SSIM_metric = tf.image.ssim(input_pred,input_template, max_val=max_val_ssim(input_pred,input_template)).numpy()[0]\n",
    "    Correlation_metric = corr(input_pred,input_template)\n",
    "    return  SSIM_metric, MSE_metric, Correlation_metric\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metrics_calculator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1074/2763944368.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics_calculator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_heatmap\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhealthy_template\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metrics_calculator' is not defined"
     ]
    }
   ],
   "source": [
    "sim, mse, cor = metrics_calculator(input_heatmap,healthy_template)\n",
    "print(sim)\n",
    "print(mse)\n",
    "print(cor.squeeze().shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncor = cor/(max_val_ssim(cor,single_arg=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ncor.squeeze())\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fd29a1856f6ae0a6b1ff5c30d8a911920bc57064f70096439f4d93b631d26313"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('kodeiri': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
